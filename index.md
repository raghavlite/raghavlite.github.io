---
layout: homepage
---

## About Me

I am a 4-th year Ph.D. student at Duke University. I am very fortunate to be advised by Prof. [Bhuwan Dhingra](https://users.cs.duke.edu/~bdhingra/). Prior to starting my PhD, I was a masters student at [UMass Amherst](https://www.umass.edu/) where I worked on amazing projects with [IESL](https://www.iesl.cs.umass.edu/). I spent four amazing years of my undergrad at [IIT Kanpur](https://www.iitk.ac.in/).

After my undergrad I spent 2 years at Xerox Research working on some text and graph problems. Over the years, I've interned at multiple places including [MetaAI](https://www.meta.ai/), [XRCI](https://india.news.xerox.com/2015/03/01/xerox-research-centre-india-concludes-xrci-open-2015/), [IESL](https://www.iesl.cs.umass.edu/).


## Research Interests
My research in Machine Learning for Natural Language Processing (NLP) focuses on enhancing performance of Large Language Models. I've worked on integrating knowledge graphs to improve reasoning in question-answering, optimizing coreference resolution efficiency. Currently, Iâ€™m interested in adaptively applying inference-time compute to improve long-form generation, embeddings, and other tasks. 

## News
- **[May. 2025]** New preprint on using smart batch mining for contrastive learning 'B3' on Arxiv. 
- **[May. 2025]** New preprint on using atomic self-consistency as a signial for preference optimizaiton 'ACPO' on Arxiv. 
- **[May. 2025]** Presented 'GenEOL' at NAACL 2025. 
- **[Dec. 2024]** Presented 'Atomic Self-Consistency' at EMNLP 2024. 
- **[Oct. 2024]** New prepreint on training-free embeddings on arXiv. Checkout GenEOL.
- **[June. 2024]** Presented 'Summary Transformation for Contrastive Learning' at NAACL.
- **[May. 2024]** Presented 'Sequence Reducible Holdout Loss for LM Pretraining' at COLING.
- **[Apr. 2024]** Presented 'Atomic Self-Consistency' at the SouthNLPSymposium (Oral).

<br>
{% include_relative _includes/publications.md %}
<br>
{% include_relative _includes/services.md %}
<br>
{% include_relative _includes/misc.md %}
